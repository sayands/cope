<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>CoPE-VideoLM</title>
        <link rel="icon" type="image/png" href="assets/logos/logo.png">
        <link rel="stylesheet" href="fonts/avenir-next/stylesheet.css">
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap">
        <link rel="stylesheet" href="icons/style.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
        <link rel="stylesheet" href="css/main.css">
        <link rel="stylesheet" href="css/runtime-comparison.css">
        <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.4/dist/chart.umd.min.js"></script>
    </head>
    <body>
        <div id="main">
            <div id="title" class="x-gradient-font">
              <span style="font-size: 80px;"><img src="assets/logos/logo.png" alt="CoPE-VideoLM Logo" style="height: 80px; vertical-align: top; margin-right: 20px;">CoPE-VideoLM</span><br>
                <span style="font-size: 28px;">Codec Primitives For Efficient Video Language Models</span>
            </div>

            <div id="authors">
                <div><a class="link" href="https://sayands.github.io/" target="_blank">Sayan Deb Sarkar</a><sup> 1,2<sup>*</sup></sup></div>
                <div><a class="link" href="https://rpautrat.github.io/" target="_blank">Rémi Pautrat</a><sup> 2 </sup></div>
                <div><a class="link" href="https://miksik.co.uk/" target="_blank">Ondrej Miksik</a><sup> 2 </sup></div>
                <div><a class="link" href="https://people.inf.ethz.ch/marc.pollefeys/" target="_blank">Marc Pollefeys</a><sup> 2,3 </sup></div>
                <div><a class="link" href="https://ir0.github.io/" target="_blank">Iro Armeni</a><sup> 1 </sup></div>
                <div><a class="link" href="https://radmahdi.github.io/Home.html" target="_blank">Mahdi Rad</a><sup> 2<sup>†</sup></sup></div>
                <div><a class="link" href="https://dusmanu.com/" target="_blank">Mihai Dusmanu</a><sup> 2<sup>†</sup></sup></div>
            </div>

            <div id="institution">
                <div><sup>1 </sup><a class="link" href="https://www.stanford.edu/" target="_blank">Stanford University</a></div>
                <div><sup>2 </sup><a class="link" href="https://www.microsoft.com/en-us/research/lab/spatial-ai-zurich/" target="_blank">Microsoft Spatial AI Lab</a></div>
                <div><sup>3 </sup><a class="link" href="https://ethz.ch/" target="_blank">ETH Zurich</a></div>
            </div>

            <div style="text-align: center; font-size: 13px; color: rgb(96, 96, 96); margin-top: 4px;">
                <span><sup>*</sup> Part of work done at Microsoft</span>
                &nbsp;&nbsp;
                <span><sup>†</sup> Equal supervision </span>
            </div>

            <!-- Institution Logos -->
            <div id="logos" style="display: flex; align-items: center; justify-content: center; gap: 40px; margin: 20px 0 8px 0; flex-wrap: wrap;">
                <a href="#" target="_blank"><img src="assets/logos/stanford.png" alt="Stanford University" style="height: 50px; object-fit: contain;"></a>
                <a href="#" target="_blank"><img src="assets/logos/gradient_spaces.png" alt="Microsoft" style="height: 50px; object-fit: contain;"></a>
                <a href="#" target="_blank"><img src="assets/logos/ethz.png" alt="ETH Zurich" style="height: 50px; object-fit: contain;"></a>
                <a href="#" target="_blank"><img src="assets/logos/microsoft.png" alt="Microsoft" style="height: 50px; object-fit: contain;"></a>
            </div>

            <div id="links">
                <div><a id="paper" href="#" target="_blank">Paper</a></div>
                <div><a id="arxiv" href="#" target="_blank"><i class="ai ai-arxiv"></i> arXiv</a></div>
                <div style="position: relative;">
                    <a id="code" href="#" target="_blank" style="pointer-events: none; opacity: 0.5; background: #e5e7eb; color: #9ca3af; cursor: not-allowed;">Code</a>
                    <span class="coming-soon-badge">Coming Soon</span>
                </div>
                <div style="position: relative;">
                    <a id="demo" href="#" target="_blank" style="pointer-events: none; opacity: 0.5; background: #e5e7eb; color: #9ca3af; cursor: not-allowed;">Demo</a>
                    <span class="coming-soon-badge">Coming Soon</span>
                </div>
            </div>

            <div id="teaser">
              <div style="width: 100%;">
                <img src="assets/figs/teaser.png" alt="CoPE-VideoLM Teaser">
              </div>
            </div>
            <div class="x-center-text" style="font-size: 20px; font-weight: 500; color: #3f3f3f; margin-top: 24px;">
              <b>TL;DR:</b> <i>Replace dense per-frame image embeddings, use video codec primitives to reduce TTFT
                by up to 86% and token usage by up to 93% while maintaining video understanding peformance.</i>
            </div>

            <div id="abstract" class="x-gradient-block">
                Video Language Models (VideoLMs) empower AI systems to understand temporal dynamics in videos. To fit to the maximum context 
                window constraint, current methods use keyframe sampling which can miss both macro-level events and micro-level details due to 
                the sparse temporal coverage. Furthermore, processing full images and their tokens for each frame incurs substantial 
                computational overhead. To address these limitations, we propose to leverage video codec primitives (specifically motion 
                vectors and residuals) which natively encode video redundancy and sparsity without requiring expensive full-image encoding for 
                most frames. To this end, we introduce lightweight transformer-based encoders that aggregate codec primitives and align their 
                representations with image encoder embeddings through a pre-training strategy  that accelerates convergence during end-to-end 
                fine-tuning. Our approach reduces the time-to-first-token by up to 86% and token usage by up to 93% compared to standard 
                VideoLMs. Moreover, by varying the keyframe and codec primitive densities we are able to maintain or exceed performance on 
                14 diverse video understanding benchmarks spanning general question answering, temporal reasoning, long-form understanding, 
                and spatial scene understanding.
            </div>


            <!-- ==================== Token Efficiency vs Accuracy ==================== -->
            <div class="x-section-title"><div class="x-gradient-font">Token Efficiency vs. Video QA Accuracy</div></div>
            <p style="text-align: left; margin-bottom: 16px;">
              Performance of LLaVA-Video (7B) at different number of keyframes per GOP, as well as in the default setup of selecting 64 keyframes regardless
              of video length compared to CoPE-VideoLM.
            </p>
            <!-- Benchmark toggle buttons -->
            <div style="display: flex; justify-content: center; gap: 8px; margin-bottom: 16px; flex-wrap: wrap;">
                <button class="benchmark-btn green is-active" id="effBtnPT" onclick="updateEfficiencyChart('perceptiontest')">PerceptionTest</button>
                <button class="benchmark-btn green" id="effBtnNQ" onclick="updateEfficiencyChart('nextqa')">NExT-QA</button>
                <button class="benchmark-btn green" id="effBtnAQ" onclick="updateEfficiencyChart('actnetqa')">ActNet-QA</button>
            </div>
            <div class="benchmark-chart-container" id="efficiencyChartContainer" style="height: 420px;">
                <canvas id="efficiencyChart"></canvas>
            </div>


            <!-- ==================== Benchmark Performance ==================== -->
            <div class="x-section-title"><div class="x-gradient-font">Benchmark Performance</div></div>
            <p>
                Comprehensive evaluation across multiple video benchmarks, covering four categories: (i) general video question answering, (ii) temporal reasoning and motion understanding, (iii) long-form and instruction-following tasks, and (iv) spatial scene understanding.
                <br> <br>
                Primary comparison with LLaVA-Video-7B (base model) alongside several closely related open-source approaches, 
                all evaluations conducted using <a href="https://github.com/EvolvingLMMs-Lab/lmms-eval" style="color: #5B93D4;" target="_blank">lmms-eval</a> to ensure consistency.
            </p>

            <!-- Benchmark selector buttons -->
            <div class="benchmark-selector">
                <div class="benchmark-btn-group">
                    <button class="benchmark-btn green is-active" data-benchmark="perceptiontest">PerceptionTest</button>
                    <button class="benchmark-btn green" data-benchmark="nextqa">NExT-QA</button>
                    <button class="benchmark-btn green" data-benchmark="actnetqa">ActNet-QA</button>
                    <button class="benchmark-btn green" data-benchmark="videomme">VideoMME</button>
                    <button class="benchmark-btn green" data-benchmark="tempcompass">TempCompass</button>
                    <button class="benchmark-btn green" data-benchmark="tomato">Tomato</button>
                    <button class="benchmark-btn green" data-benchmark="cvrres">CVRR-ES</button>
                    <button class="benchmark-btn green" data-benchmark="mvbench">MVBench</button>
                    <button class="benchmark-btn green" data-benchmark="videott">Video-TT</button>
                    <button class="benchmark-btn green" data-benchmark="videommmu">Video-MMMU</button>
                    <button class="benchmark-btn green" data-benchmark="lvbench">LVBench</button>
                    <button class="benchmark-btn green" data-benchmark="longvideobench">LongVideoBench</button>
                </div>
            </div>

            <!-- Chart canvas -->
            <div class="benchmark-chart-container">
                <canvas id="benchmarkChart"></canvas>
            </div>


            <!-- ==================== Interactive Runtime Comparison ==================== -->
            <div class="x-section-title"><div class="x-gradient-font">Interactive Runtime Comparison</div></div>
            <p>
              User chat experience comparing LLaVA-Video and CoPE-VideoLM at 1 FPS video input.
            </p>
            <div id="runtime-comparison">
              <div class="rc-content">
                <!-- LEFT PANE -->
                <section class="rc-left-pane">
                  <div class="rc-hero-video-wrapper">
                    <video class="rc-hero-video" id="rcHeroVideo" muted loop playsinline autoplay>
                      <source src="assets/videos/video_example1.mp4" type="video/mp4" id="rcVideoSource" />
                      Your browser does not support the video tag.
                    </video>
                  </div>
                  <div class="rc-video-caption" id="rcVideoCaption">Input Video</div>

                  <!-- Carousel Navigation -->
                  <div class="rc-carousel-nav">
                    <button class="rc-carousel-arrow" id="rcPrevBtn" aria-label="Previous video">&#8249;</button>
                    <div class="rc-carousel-dots" id="rcCarouselDots"></div>
                    <button class="rc-carousel-arrow" id="rcNextBtn" aria-label="Next video">&#8250;</button>
                  </div>


                </section>

                <!-- RIGHT PANE: PHONES -->
                <section class="rc-right-pane">
                  <div class="rc-phones">
                    <!-- PHONE 1 -->
                    <div class="rc-phone">
                      <div class="rc-phone-shell" id="rc-phone-1">
                        <div class="rc-phone-notch"></div>
                        <div class="rc-phone-screen">
                          <div class="rc-status-row">
                            <div class="rc-status-left">
                              <span class="rc-status-dot"></span>
                              <span>Chat</span>
                            </div>
                            <div class="rc-status-right">
                              <span>9:41</span>
                              <span class="rc-status-bar-icon"></span>
                            </div>
                          </div>

                          <div class="rc-chat-header">
                            <div class="rc-chat-contact-name">LLaVA-Video</div>
                          </div>

                          <div class="rc-chat-window" data-role="rc-chat-window"></div>
                        </div>
                      </div>
                    </div>

                    <!-- PHONE 2 -->
                    <div class="rc-phone">
                      <div class="rc-phone-shell" id="rc-phone-2">
                        <div class="rc-phone-notch"></div>
                        <div class="rc-phone-screen">
                          <div class="rc-status-row">
                            <div class="rc-status-left">
                              <span class="rc-status-dot"></span>
                              <span>Chat</span>
                            </div>
                            <div class="rc-status-right">
                              <span>9:41</span>
                              <span class="rc-status-bar-icon"></span>
                            </div>
                          </div>

                          <div class="rc-chat-header">
                            <div class="rc-chat-contact-name">CoPE-VideoLM</div>
                          </div>

                          <div class="rc-chat-window" data-role="rc-chat-window"></div>
                        </div>
                      </div>
                    </div>
                  </div>

                  <!-- Results Summary Panel -->
                  <div class="rc-progress-panel" id="rcProgressPanel">
                    <div class="rc-progress-summary" id="rcProgressSummary"></div>
                  </div>
                </section>
              </div>

            </div>

            <!-- ==================== Runtime and Memory ==================== -->
            <div class="x-section-title"><div class="x-gradient-font">Runtime and Memory</div></div>

            <!-- Subsection: Runtime Comparison -->
            <div class="x-subsection-title">Runtime Comparison</div>
            <p>
                TTFT and E2EL for generating 64 text tokens at several keyframe densities compared to the 64 keyframe baseline at 1 FPS.
            </p>
            <!-- Metric toggle buttons -->
            <div style="display: flex; justify-content: center; gap: 8px; margin-bottom: 16px; flex-wrap: wrap;">
                <button class="benchmark-btn green is-active" id="runtimeBtnTTFT" onclick="updateRuntimeChart('ttft')">TTFT</button>
                <button class="benchmark-btn green" id="runtimeBtnE2EL" onclick="updateRuntimeChart('e2el')">E2EL</button>
                <button class="benchmark-btn green" id="runtimeBtnBoth" onclick="updateRuntimeChart('both')">Both</button>
            </div>
            <div class="benchmark-chart-container" id="runtimeChartContainer" style="height: 320px;">
                <canvas id="runtimeChart"></canvas>
            </div>

            <!-- Subsection: Token Budget vs Video Length -->
            <div class="x-subsection-title">Token Budget vs. Video Length</div>
            <!-- <p>
                The token efficiency of the &Delta;-token formulation enables scaling to sequences previously inaccessible to open-source models. Standard dense RGB sampling saturates quickly, limiting coverage to short sequences as memory constraints are rapidly encountered. In contrast, CoPE-VideoLM exhibits a highly efficient relationship between video length and token budget &mdash; our most compact configuration allows processing videos up to 8 hours in duration (at 1 FPS) within a 1M token context, an order-of-magnitude increase over the baseline.
            </p> -->

            <p>
              Theoretical plot showing token efficiency across configurations - enable scaling to longer videos without exceeding context limits.
            </p>
            <div class="benchmark-chart-container" id="scalingChartContainer" style="height: 440px;">
                <canvas id="scalingChart"></canvas>
            </div>


            <!-- ==================== Method ==================== -->
            <div class="x-section-title"><div class="x-gradient-font">Methodology</div></div>
            <p>
                <img class="pipeline-img" src="assets/figs/pipeline.png" alt="Overview of the method" style="width: 100%;">
            </p>
            <p>
                Given a video in its raw codec representation, our framework leverages the GOP structure for efficient, codec-aware tokenization.
                <i>I-frames</i> are processed by a standard frozen vision encoder (&phi;<sub>RGB</sub>) to produce dense RGB tokens.
                <i>P-frames</i>, however, bypass full RGB decoding. Their raw components, motion vectors and residuals, are instead fed into our
                lightweight &Delta;-Encoder (&phi;<sub>&Delta;</sub>) to generate a small set of highly compact &Delta;-tokens. The final token stream,
                an interleaved sequence of I-frame tokens and &Delta;-tokens, is consumed by the LLM, enabling dense temporal coverage at a fraction
                of the standard token count and runtime.
            </p>

            <div class="delta-encoder-row" style="margin-top: 50px;">
                <div class="delta-encoder-img">
                    <img class="pipeline-img" src="assets/figs/delta_encoder.png" alt="Delta Encoder architecture">
                </div>
                <div class="delta-encoder-text">
                    <p>
                        <b>&Delta;-Encoder</b> processes motion vectors and residuals through two lightweight branches designed to extract and compress codec-domain information. The resulting motion and residual tokens are concatenated to form the &Delta;-tokens used for P-frames, providing an efficient representation that is projected to the RGB token space during pre-training.
                    </p>
                    <p style="margin-top: 10px;">
                        <b>Training Paradigm.</b> First, the &Delta;-Encoder is <i>pre-trained</i> to align its output with the frozen vision encoder. The resulting features are aligned with ground-truth image tokens via a patch-wise MSE loss, enforcing spatially consistent alignment across patches. After pre-training, the &Delta;-Encoder is integrated into the VideoLM for end-to-end fine-tuning &mdash; the reference-conditioned branches from pre-training are dropped, so no RGB reference frames are processed for P-frames. This yields a substantial compute and memory reduction while keeping the standard instruction tuning objective unchanged.
                    </p>
                </div>
            </div>


            <!-- ==================== Acknowledgements ==================== -->
            <div class="x-section-title"><div class="x-gradient-font">Acknowledgements</div></div>
            <p>
                <i>
                    We would like to thank (in alphabetical order): Isar Meijer and Krzysztof Waraksa from Microsoft for help with training pipeline setup; Tao Sun and Jianhao Zheng from Stanford for feedback at different stages of the project.<br>
                    Website template inspired by <a href="https://sayands.github.io/guideflow3d/" style="color: #5B93D4;" target="_blank">GuideFlow3D</a>.
                </i>
            </p>


            <!-- ==================== Citation ==================== -->
            <div class="x-section-title"><div class="x-gradient-font">Citation</div></div>
            <p>
                If you find our work useful, please consider citing:
            </p>
            <p class="bibtex x-gradient-block">
              @misc{cope_videolm,
                title={CoPE-VideoLM: Codec Primitives For Efficient Video Language Models}, 
                author={Sayan Deb Sarkar and R\'emi Pautrat and Ondrej Miksik and Marc Pollefeys and Iro Armeni and Mahdi Rad and Mihai Dusmanu},
                year={2026},
                eprint={TODO},
                archivePrefix={arXiv},
                primaryClass={cs.CV},
                url={TODO}, 
          }</p>
        </div>

        <!-- Bottom Bar -->
        <div id="bottombar">
            <div class="row">
                <div style="white-space: nowrap;"><span>C<span style="font-size: 10px;">O</span>PE-V<span style="font-size: 10px;">IDEO</span>LM</span>: Codec Primitives For Efficient Video Language Models</div>
                <div style="display: flex; flex-direction: row; align-items: center; gap: 8px; flex-wrap: wrap; justify-content: center; white-space: nowrap;">
                    <a href="mailto:sdsarkar@stanford.edu">Contact Us</a>
                    <span style="width: 1px; height: 12px; background-color: rgba(255, 255, 255, 0.7);"></span>
                    <a href="https://go.microsoft.com/fwlink/?LinkId=521839">Privacy &amp; Cookies</a>
                    <span style="width: 1px; height: 12px; background-color: rgba(255, 255, 255, 0.7);"></span>
                    <a href="https://go.microsoft.com/fwlink/?linkid=2259814">Consumer Health Privacy</a>
                    <span style="width: 1px; height: 12px; background-color: rgba(255, 255, 255, 0.7);"></span>
                    <a href="https://go.microsoft.com/fwlink/?LinkID=246338">Terms of Use</a>
                    <span style="width: 1px; height: 12px; background-color: rgba(255, 255, 255, 0.7);"></span>
                    <a href="https://go.microsoft.com/fwlink/?linkid=2196228">Trademarks</a>
                    <span style="width: 1px; height: 12px; background-color: rgba(255, 255, 255, 0.7);"></span>
                    <span>&copy; 2025 Microsoft</span>
                </div>
            </div>
        </div>

        <!-- ==================== Token Efficiency Chart Script ==================== -->
        <script src="js/efficiency-chart.js"></script>

        <!-- ==================== Benchmark Chart Script ==================== -->
        <script src="js/benchmarks.js"></script>

        <!-- ==================== Runtime Comparison Script ==================== -->
        <script src="js/runtime-comparison.js"></script>

        <!-- ==================== Runtime Table Chart Script ==================== -->
        <script src="js/runtime-chart.js"></script>

        <!-- ==================== Scaling Chart Script ==================== -->
        <script src="js/scaling-chart.js"></script>
    </body>
</html>
